{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Roberta_wTeamSentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMBJkQpJbigc"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOib12-jbxl3"
      },
      "source": [
        "#IMPORT LIBS\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from transformers import TFAutoModel,RobertaTokenizer, TFRobertaModel, RobertaTokenizer, RobertaModel\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score,confusion_matrix,accuracy_score,recall_score,precision_score,classification_report\n",
        "from keras.models import load_model\n",
        "import re\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDzbZ4O7bz0n",
        "outputId": "45c30d60-2f15-436e-9f4e-145f20f7e316"
      },
      "source": [
        "#GET RAW DATA\n",
        "df = pd.read_csv('data.csv')\n",
        "df = df.fillna('')\n",
        "print(df.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Comment  ... HumanSentiment\n",
            "0                    Good job everyone and happy 4th  ...       positive\n",
            "1  Holding my CLOV call! Tendies for breakfast ar...  ...       positive\n",
            "2  I went to ikea with my cousin today and holy s...  ...       negative\n",
            "3  I’m a fucking moron and I’m never investing again  ...       negative\n",
            "4  I can’t wait to go all in on TSLA calls for ne...  ...       positive\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zTCIBpsb1kJ",
        "outputId": "cf20626a-d286-4e09-9aa6-560fb3ffbeab"
      },
      "source": [
        "#PARTITION AND SPLIT DATA\n",
        "df2 = df[['ProcessedComments', 'HumanSentiment']]\n",
        "\n",
        "test = df['HumanSentiment'].value_counts()\n",
        "\n",
        "df2['sentiment_numeric']  = pd.factorize(df2[\"HumanSentiment\"])[0] \n",
        "\n",
        "dictionary = pd.Series(df2[\"HumanSentiment\"].values,index=df2['sentiment_numeric']).to_dict()\n",
        "print(dictionary)\n",
        "np.save('sentiments.npy', dictionary)\n",
        "\n",
        "df2 = df2[['ProcessedComments', 'sentiment_numeric']]\n",
        "print(df2.head())\n",
        "print(len(df2))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "df_subset_train_model, df_subset_val_model = train_test_split(df2, test_size=0.1)\n",
        "\n",
        "\n",
        "df2 = df_subset_train_model[['ProcessedComments','sentiment_numeric']]\n",
        "print(len(df2))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'positive', 1: 'negative', 2: 'neutral'}\n",
            "                                   ProcessedComments  sentiment_numeric\n",
            "0                    Good job everyone and happy 4th                  0\n",
            "1  Holding my CLOV call Tendies for breakfast are...                  0\n",
            "2  I went to ikea with my cousin today and holy s...                  1\n",
            "3    Im a fucking moron and Im never investing again                  1\n",
            "4  I cant wait to go all in on TSLA calls for nex...                  0\n",
            "2500\n",
            "2250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzE1DLvMb8RI",
        "outputId": "388f4a3b-ac83-4c03-88ca-00e366a1bc90"
      },
      "source": [
        "#%ROBERTA SETUP\n",
        "seq_len = 512\n",
        "num_samples = len(df2)\n",
        "\n",
        "Xids = np.zeros((num_samples, 512))\n",
        "Xmask = np.zeros((num_samples, 512))\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "#from transformers import AutoTokenizer, TFAutoModel\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"kamalkraj/deberta-base\")\n",
        "\n",
        "for i, phrase in enumerate(df2['ProcessedComments']):\n",
        "    tokens = tokenizer.encode_plus(phrase, max_length=seq_len, truncation=True,\n",
        "                                   padding='max_length', add_special_tokens=True,\n",
        "                                   return_tensors='tf')\n",
        "    Xids[i, :] = tf.cast(tokens['input_ids'],tf.float64)\n",
        "    Xmask[i, :] = tf.cast(tokens['attention_mask'],tf.float64)\n",
        "    \n",
        "arr = df2['sentiment_numeric'].values\n",
        "print(arr)\n",
        "\n",
        "labels = np.zeros((num_samples, arr.max()+1))\n",
        "print(labels.shape)\n",
        "\n",
        "labels[np.arange(num_samples), arr] = 1\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 2 ... 1 2 1]\n",
            "(2250, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bm_3XXkcDWy",
        "outputId": "8004d376-975f-46d2-ff4f-8729a17ce10d"
      },
      "source": [
        "#PREPARE DATA FOR TF MODEL\n",
        "import tensorflow as tf\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((Xids,Xmask,labels))\n",
        "\n",
        "def map_func(input_ids, masks, labels):                                    \n",
        "    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
        "\n",
        "dataset = dataset.map(map_func)\n",
        "\n",
        "batch_size = 13\n",
        "dataset = dataset.shuffle(10000).batch(batch_size,drop_remainder=True)\n",
        "\n",
        "split = 0.80\n",
        "size = int((num_samples/batch_size) * split)\n",
        "\n",
        "train_ds = dataset.take(size)\n",
        "val_ds = dataset.skip(size)\n",
        "print(train_ds)\n",
        "print(val_ds)\n",
        "del dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<TakeDataset shapes: ({input_ids: (13, 512), attention_mask: (13, 512)}, (13, 3)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float64)>\n",
            "<SkipDataset shapes: ({input_ids: (13, 512), attention_mask: (13, 512)}, (13, 3)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYFiQgc3cGbk",
        "outputId": "d2daa30d-aa37-49d6-eae7-9b42e679ad6e"
      },
      "source": [
        "#%%RUN TF MODEL 100 EPOCHS\n",
        "\n",
        "from transformers import TFAutoModel,RobertaTokenizer, TFRobertaModel\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, min_delta = 0.1, verbose = 1)\n",
        "\n",
        "bert = TFRobertaModel.from_pretrained(\"roberta-base\")\n",
        "print(bert.summary())\n",
        "\n",
        "input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
        "\n",
        "embeddings = bert.roberta(input_ids, attention_mask=mask)[1]\n",
        "\n",
        "x = tf.keras.layers.Dense(1024,activation='relu')(embeddings)\n",
        "y = tf.keras.layers.Dense(arr.max()+1,activation='softmax', name = 'outputs')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input_ids,mask], outputs=y)\n",
        "print(model.summary())\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-7,decay=1e-6)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "model.compile(optimizer=optimizer, loss = loss, metrics = [acc])\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs = 100#,\n",
        "    #callbacks=[early_stopping]\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_roberta_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "roberta (TFRobertaMainLayer) multiple                  124645632 \n",
            "=================================================================\n",
            "Total params: 124,645,632\n",
            "Trainable params: 124,645,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "roberta (TFRobertaMainLayer)    TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         787456      roberta[0][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "outputs (Dense)                 (None, 3)            3075        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 125,436,163\n",
            "Trainable params: 125,436,163\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "138/138 [==============================] - 141s 947ms/step - loss: 1.1126 - accuracy: 0.2341 - val_loss: 1.1074 - val_accuracy: 0.2615\n",
            "Epoch 2/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 1.1047 - accuracy: 0.3155 - val_loss: 1.1015 - val_accuracy: 0.3604\n",
            "Epoch 3/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 1.0987 - accuracy: 0.3445 - val_loss: 1.0974 - val_accuracy: 0.3297\n",
            "Epoch 4/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 1.0919 - accuracy: 0.3679 - val_loss: 1.0906 - val_accuracy: 0.3714\n",
            "Epoch 5/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 1.0874 - accuracy: 0.4136 - val_loss: 1.0850 - val_accuracy: 0.4615\n",
            "Epoch 6/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 1.0847 - accuracy: 0.4420 - val_loss: 1.0832 - val_accuracy: 0.4703\n",
            "Epoch 7/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 1.0817 - accuracy: 0.4415 - val_loss: 1.0795 - val_accuracy: 0.5253\n",
            "Epoch 8/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0783 - accuracy: 0.4353 - val_loss: 1.0765 - val_accuracy: 0.4703\n",
            "Epoch 9/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0770 - accuracy: 0.4147 - val_loss: 1.0728 - val_accuracy: 0.4176\n",
            "Epoch 10/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0757 - accuracy: 0.4231 - val_loss: 1.0743 - val_accuracy: 0.4286\n",
            "Epoch 11/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 1.0733 - accuracy: 0.4164 - val_loss: 1.0783 - val_accuracy: 0.4066\n",
            "Epoch 12/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 1.0737 - accuracy: 0.4153 - val_loss: 1.0745 - val_accuracy: 0.4066\n",
            "Epoch 13/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 1.0733 - accuracy: 0.4108 - val_loss: 1.0765 - val_accuracy: 0.4176\n",
            "Epoch 14/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 1.0682 - accuracy: 0.4125 - val_loss: 1.0735 - val_accuracy: 0.4044\n",
            "Epoch 15/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 1.0674 - accuracy: 0.4197 - val_loss: 1.0549 - val_accuracy: 0.4330\n",
            "Epoch 16/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 1.0663 - accuracy: 0.4080 - val_loss: 1.0648 - val_accuracy: 0.4066\n",
            "Epoch 17/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0690 - accuracy: 0.4041 - val_loss: 1.0645 - val_accuracy: 0.4044\n",
            "Epoch 18/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0695 - accuracy: 0.4147 - val_loss: 1.0633 - val_accuracy: 0.4088\n",
            "Epoch 19/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0662 - accuracy: 0.4197 - val_loss: 1.0680 - val_accuracy: 0.4154\n",
            "Epoch 20/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0681 - accuracy: 0.4231 - val_loss: 1.0668 - val_accuracy: 0.4088\n",
            "Epoch 21/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0623 - accuracy: 0.4270 - val_loss: 1.0423 - val_accuracy: 0.4725\n",
            "Epoch 22/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0648 - accuracy: 0.4192 - val_loss: 1.0631 - val_accuracy: 0.4308\n",
            "Epoch 23/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0646 - accuracy: 0.4253 - val_loss: 1.0627 - val_accuracy: 0.4374\n",
            "Epoch 24/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0614 - accuracy: 0.4448 - val_loss: 1.0546 - val_accuracy: 0.4769\n",
            "Epoch 25/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0613 - accuracy: 0.4482 - val_loss: 1.0668 - val_accuracy: 0.4308\n",
            "Epoch 26/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0593 - accuracy: 0.4470 - val_loss: 1.0670 - val_accuracy: 0.4462\n",
            "Epoch 27/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0553 - accuracy: 0.4632 - val_loss: 1.0566 - val_accuracy: 0.4923\n",
            "Epoch 28/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0541 - accuracy: 0.4654 - val_loss: 1.0426 - val_accuracy: 0.4527\n",
            "Epoch 29/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0517 - accuracy: 0.4576 - val_loss: 1.0530 - val_accuracy: 0.4835\n",
            "Epoch 30/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0435 - accuracy: 0.4961 - val_loss: 1.0454 - val_accuracy: 0.4769\n",
            "Epoch 31/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0477 - accuracy: 0.4794 - val_loss: 1.0525 - val_accuracy: 0.4835\n",
            "Epoch 32/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0485 - accuracy: 0.4810 - val_loss: 1.0342 - val_accuracy: 0.5077\n",
            "Epoch 33/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0407 - accuracy: 0.4955 - val_loss: 1.0480 - val_accuracy: 0.4791\n",
            "Epoch 34/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0383 - accuracy: 0.4989 - val_loss: 1.0200 - val_accuracy: 0.5121\n",
            "Epoch 35/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0355 - accuracy: 0.5039 - val_loss: 1.0221 - val_accuracy: 0.5187\n",
            "Epoch 36/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0300 - accuracy: 0.5045 - val_loss: 1.0128 - val_accuracy: 0.5165\n",
            "Epoch 37/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0146 - accuracy: 0.5156 - val_loss: 1.0180 - val_accuracy: 0.5319\n",
            "Epoch 38/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0104 - accuracy: 0.5184 - val_loss: 1.0091 - val_accuracy: 0.5011\n",
            "Epoch 39/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0022 - accuracy: 0.5385 - val_loss: 1.0234 - val_accuracy: 0.5077\n",
            "Epoch 40/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 1.0022 - accuracy: 0.5301 - val_loss: 0.9738 - val_accuracy: 0.5451\n",
            "Epoch 41/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9914 - accuracy: 0.5401 - val_loss: 0.9771 - val_accuracy: 0.5319\n",
            "Epoch 42/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9769 - accuracy: 0.5530 - val_loss: 0.9768 - val_accuracy: 0.5319\n",
            "Epoch 43/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9710 - accuracy: 0.5569 - val_loss: 0.9597 - val_accuracy: 0.5648\n",
            "Epoch 44/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9647 - accuracy: 0.5491 - val_loss: 0.9614 - val_accuracy: 0.5429\n",
            "Epoch 45/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9622 - accuracy: 0.5507 - val_loss: 0.9309 - val_accuracy: 0.5890\n",
            "Epoch 46/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9552 - accuracy: 0.5535 - val_loss: 0.9454 - val_accuracy: 0.5516\n",
            "Epoch 47/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9483 - accuracy: 0.5569 - val_loss: 0.9460 - val_accuracy: 0.5341\n",
            "Epoch 48/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9458 - accuracy: 0.5602 - val_loss: 0.9093 - val_accuracy: 0.5912\n",
            "Epoch 49/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9326 - accuracy: 0.5764 - val_loss: 0.9040 - val_accuracy: 0.5648\n",
            "Epoch 50/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9304 - accuracy: 0.5775 - val_loss: 0.9127 - val_accuracy: 0.5648\n",
            "Epoch 51/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9261 - accuracy: 0.5753 - val_loss: 0.9389 - val_accuracy: 0.5516\n",
            "Epoch 52/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9217 - accuracy: 0.5831 - val_loss: 0.9186 - val_accuracy: 0.5604\n",
            "Epoch 53/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9223 - accuracy: 0.5847 - val_loss: 0.9037 - val_accuracy: 0.5846\n",
            "Epoch 54/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9132 - accuracy: 0.5909 - val_loss: 0.8781 - val_accuracy: 0.6198\n",
            "Epoch 55/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9071 - accuracy: 0.5881 - val_loss: 0.9115 - val_accuracy: 0.5495\n",
            "Epoch 56/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9244 - accuracy: 0.5652 - val_loss: 0.8602 - val_accuracy: 0.6198\n",
            "Epoch 57/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9174 - accuracy: 0.5797 - val_loss: 0.8645 - val_accuracy: 0.6044\n",
            "Epoch 58/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.9137 - accuracy: 0.5775 - val_loss: 0.8430 - val_accuracy: 0.6132\n",
            "Epoch 59/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8933 - accuracy: 0.6048 - val_loss: 0.8892 - val_accuracy: 0.6000\n",
            "Epoch 60/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8844 - accuracy: 0.5925 - val_loss: 0.8929 - val_accuracy: 0.5978\n",
            "Epoch 61/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 0.8785 - accuracy: 0.5992 - val_loss: 0.8578 - val_accuracy: 0.5956\n",
            "Epoch 62/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8869 - accuracy: 0.5942 - val_loss: 0.8321 - val_accuracy: 0.6396\n",
            "Epoch 63/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8785 - accuracy: 0.5998 - val_loss: 0.8850 - val_accuracy: 0.5868\n",
            "Epoch 64/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8880 - accuracy: 0.5914 - val_loss: 0.8027 - val_accuracy: 0.6418\n",
            "Epoch 65/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8843 - accuracy: 0.5987 - val_loss: 0.8799 - val_accuracy: 0.5978\n",
            "Epoch 66/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8791 - accuracy: 0.5998 - val_loss: 0.8447 - val_accuracy: 0.6154\n",
            "Epoch 67/100\n",
            "138/138 [==============================] - 129s 934ms/step - loss: 0.8622 - accuracy: 0.6137 - val_loss: 0.7942 - val_accuracy: 0.6659\n",
            "Epoch 68/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8680 - accuracy: 0.6104 - val_loss: 0.8460 - val_accuracy: 0.6330\n",
            "Epoch 69/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8695 - accuracy: 0.6076 - val_loss: 0.8298 - val_accuracy: 0.6242\n",
            "Epoch 70/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8509 - accuracy: 0.6182 - val_loss: 0.8127 - val_accuracy: 0.6352\n",
            "Epoch 71/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8639 - accuracy: 0.6093 - val_loss: 0.8193 - val_accuracy: 0.6440\n",
            "Epoch 72/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8514 - accuracy: 0.6165 - val_loss: 0.8220 - val_accuracy: 0.6396\n",
            "Epoch 73/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8488 - accuracy: 0.6243 - val_loss: 0.8543 - val_accuracy: 0.6176\n",
            "Epoch 74/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8527 - accuracy: 0.6204 - val_loss: 0.7694 - val_accuracy: 0.6527\n",
            "Epoch 75/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8313 - accuracy: 0.6355 - val_loss: 0.7743 - val_accuracy: 0.6725\n",
            "Epoch 76/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8507 - accuracy: 0.6182 - val_loss: 0.7891 - val_accuracy: 0.6549\n",
            "Epoch 77/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8329 - accuracy: 0.6288 - val_loss: 0.8078 - val_accuracy: 0.6440\n",
            "Epoch 78/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8383 - accuracy: 0.6232 - val_loss: 0.7733 - val_accuracy: 0.6725\n",
            "Epoch 79/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8515 - accuracy: 0.6215 - val_loss: 0.8028 - val_accuracy: 0.6330\n",
            "Epoch 80/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8409 - accuracy: 0.6310 - val_loss: 0.8257 - val_accuracy: 0.6242\n",
            "Epoch 81/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8360 - accuracy: 0.6343 - val_loss: 0.7930 - val_accuracy: 0.6571\n",
            "Epoch 82/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8300 - accuracy: 0.6276 - val_loss: 0.7818 - val_accuracy: 0.6637\n",
            "Epoch 83/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8274 - accuracy: 0.6394 - val_loss: 0.7498 - val_accuracy: 0.6901\n",
            "Epoch 84/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8279 - accuracy: 0.6377 - val_loss: 0.7556 - val_accuracy: 0.6659\n",
            "Epoch 85/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8241 - accuracy: 0.6388 - val_loss: 0.7556 - val_accuracy: 0.6769\n",
            "Epoch 86/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8183 - accuracy: 0.6421 - val_loss: 0.7605 - val_accuracy: 0.6703\n",
            "Epoch 87/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8128 - accuracy: 0.6488 - val_loss: 0.7790 - val_accuracy: 0.6571\n",
            "Epoch 88/100\n",
            "138/138 [==============================] - 129s 932ms/step - loss: 0.8204 - accuracy: 0.6410 - val_loss: 0.7763 - val_accuracy: 0.6527\n",
            "Epoch 89/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8167 - accuracy: 0.6421 - val_loss: 0.7608 - val_accuracy: 0.6747\n",
            "Epoch 90/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.7987 - accuracy: 0.6572 - val_loss: 0.7837 - val_accuracy: 0.6681\n",
            "Epoch 91/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8132 - accuracy: 0.6483 - val_loss: 0.7754 - val_accuracy: 0.6571\n",
            "Epoch 92/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8051 - accuracy: 0.6505 - val_loss: 0.7422 - val_accuracy: 0.6725\n",
            "Epoch 93/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8109 - accuracy: 0.6488 - val_loss: 0.7419 - val_accuracy: 0.6989\n",
            "Epoch 94/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.7953 - accuracy: 0.6527 - val_loss: 0.7682 - val_accuracy: 0.6505\n",
            "Epoch 95/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.7910 - accuracy: 0.6589 - val_loss: 0.7004 - val_accuracy: 0.7099\n",
            "Epoch 96/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.7986 - accuracy: 0.6616 - val_loss: 0.7286 - val_accuracy: 0.6725\n",
            "Epoch 97/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.8037 - accuracy: 0.6488 - val_loss: 0.7331 - val_accuracy: 0.6813\n",
            "Epoch 98/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.7938 - accuracy: 0.6494 - val_loss: 0.7360 - val_accuracy: 0.6901\n",
            "Epoch 99/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.7985 - accuracy: 0.6527 - val_loss: 0.7222 - val_accuracy: 0.6945\n",
            "Epoch 100/100\n",
            "138/138 [==============================] - 129s 933ms/step - loss: 0.7941 - accuracy: 0.6460 - val_loss: 0.7374 - val_accuracy: 0.6967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "IYNtU-5QcLUN",
        "outputId": "db2e33f2-e9ab-4c19-d66a-01c9535aa40f"
      },
      "source": [
        "#SAVE MODEL\n",
        "model.save('sentiment_model_teamsentiment')\n",
        "\n",
        "!zip -r /content/sentiment_model_teamsentiment.zip /content/sentiment_model_teamsentiment\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/sentiment_model_teamsentiment.zip\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: sentiment_model_teamsentiment/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: sentiment_model_teamsentiment/assets\n",
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/sentiment_model_teamsentiment/ (stored 0%)\n",
            "  adding: content/sentiment_model_teamsentiment/keras_metadata.pb (deflated 95%)\n",
            "  adding: content/sentiment_model_teamsentiment/saved_model.pb (deflated 92%)\n",
            "  adding: content/sentiment_model_teamsentiment/assets/ (stored 0%)\n",
            "  adding: content/sentiment_model_teamsentiment/variables/ (stored 0%)\n",
            "  adding: content/sentiment_model_teamsentiment/variables/variables.data-00000-of-00001 (deflated 27%)\n",
            "  adding: content/sentiment_model_teamsentiment/variables/variables.index (deflated 80%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ac5dee40-7e4a-4ec8-9ef3-e26146e249c1\", \"sentiment_model_teamsentiment.zip\", 1099454501)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GazRBNb1cUb4",
        "outputId": "27a05183-ac62-48d5-9558-9264a110bccc"
      },
      "source": [
        "#%% TEST MODEL\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def prep_data(text):\n",
        "    tokens = tokenizer.encode_plus(text, max_length=512, truncation=True,\n",
        "                                   padding='max_length', add_special_tokens=True,#return_token_type_id=False,\n",
        "                                   return_tensors='tf')\n",
        "    return{\n",
        "        'input_ids': tf.cast(tokens['input_ids'], tf.float64),\n",
        "        'attention_mask': tf.cast(tokens['attention_mask'], tf.float64)\n",
        "        }\n",
        "\n",
        "#test = prep_data('I hate all this')\n",
        "#test = prep_data('GME to the Moon!')\n",
        "#test = prep_data('I love this')\n",
        "probs = model.predict(test)\n",
        "\n",
        "np.argmax(probs[0])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EpstUcMcqXR",
        "outputId": "e8f03c8d-e45e-4315-c804-1e3fba557e9a"
      },
      "source": [
        "# TEST MODEL ON VALIDATION DATA\n",
        "df_subset_val_model = df_subset_val_model.reset_index(drop=True)\n",
        "#del df_subset_val_model['index']\n",
        "df_subset_val_model.head()\n",
        "\n",
        "cor = df_subset_val_model['ProcessedComments'].apply(prep_data)\n",
        "\n",
        "\n",
        "pred = [np.argmax((model.predict(cor[i]))[0]) for i in tqdm(range(len(cor)))]\n",
        "pred2 = [model.predict(cor[i]) for i in tqdm(range(len(cor)))]\n",
        "df_subset_val_model['predsentiment'] = pred\n",
        "df_subset_val_model['predsentiment2'] = pred2\n",
        "\n",
        "print(df_subset_val_model.head())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 240/250 [00:22<00:00, 10.67it/s]\u001b[A\n",
            " 97%|█████████▋| 242/250 [00:23<00:00, 10.57it/s]\u001b[A\n",
            " 98%|█████████▊| 244/250 [00:23<00:00, 10.47it/s]\u001b[A\n",
            " 98%|█████████▊| 246/250 [00:23<00:00, 10.49it/s]\u001b[A\n",
            " 99%|█████████▉| 248/250 [00:23<00:00, 10.36it/s]\u001b[A\n",
            "100%|██████████| 250/250 [00:23<00:00, 10.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   ProcessedComments  ...                          predsentiment2\n",
            "0  Stocks only go up Unless youre Chinese in whic...  ...   [[0.09437902, 0.5947556, 0.31086537]]\n",
            "1  Seriously considering contacting the crazy ex ...  ...  [[0.04620931, 0.8963726, 0.057418104]]\n",
            "2  Pltr is a long hold why is everyone in such a ...  ...   [[0.07441355, 0.7969895, 0.12859693]]\n",
            "3  i just want to get rich enough to fuck AOC in ...  ...   [[0.32733282, 0.4882121, 0.18445505]]\n",
            "4  Trading hack for you rookies Become a pattern ...  ...  [[0.16728131, 0.49700892, 0.33570972]]\n",
            "\n",
            "[5 rows x 4 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwkzIlJecta5",
        "outputId": "81b5e3de-9fab-44fa-8d25-2698bb67dedd"
      },
      "source": [
        "#%% CLASSIFICATION REPORT\n",
        "print('\\nclassification report:\\n', classification_report(df_subset_val_model['sentiment_numeric'],df_subset_val_model['predsentiment']))\n",
        "\n",
        "df_confusion = pd.crosstab(df_subset_val_model['sentiment_numeric'], df_subset_val_model['predsentiment'], rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
        "print(df_confusion)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.71      0.69       107\n",
            "           1       0.61      0.83      0.70        82\n",
            "           2       0.54      0.21      0.31        61\n",
            "\n",
            "    accuracy                           0.63       250\n",
            "   macro avg       0.61      0.58      0.56       250\n",
            "weighted avg       0.62      0.63      0.60       250\n",
            "\n",
            "Predicted    0    1   2  All\n",
            "Actual                      \n",
            "0           76   25   6  107\n",
            "1            9   68   5   82\n",
            "2           29   19  13   61\n",
            "All        114  112  24  250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49cjSeQKcvZ6",
        "outputId": "7feac0a8-d8a2-48e7-fda8-83677c8fcd7f"
      },
      "source": [
        "df_subset_val_model.predsentiment2.apply(str).value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.66461766 0.04147586 0.29390648]]    2\n",
              "[[0.83657694 0.0675445  0.0958785 ]]    1\n",
              "[[0.07257944 0.68512994 0.24229051]]    1\n",
              "[[0.8139321  0.0926933  0.09337454]]    1\n",
              "[[0.1391712 0.638525  0.2223038]]       1\n",
              "                                       ..\n",
              "[[0.03962601 0.9002433  0.06013076]]    1\n",
              "[[0.78351676 0.07291437 0.14356884]]    1\n",
              "[[0.1511761  0.7352238  0.11360016]]    1\n",
              "[[0.64896655 0.20395236 0.14708109]]    1\n",
              "[[0.43210772 0.31224355 0.25564873]]    1\n",
              "Name: predsentiment2, Length: 249, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nKegshocyCT"
      },
      "source": [
        "df_subset_train_model = df_subset_train_model.reset_index(drop=True)\n",
        "#del df_subset_val_model['index']\n",
        "df_subset_train_model.head()\n",
        "\n",
        "cor = df_subset_train_model['ProcessedComments'].apply(prep_data)\n",
        "\n",
        "\n",
        "pred = [np.argmax((model.predict(cor[i]))[0]) for i in tqdm(range(len(cor)))]\n",
        "pred2 = [model.predict(cor[i]) for i in tqdm(range(len(cor)))]\n",
        "df_subset_train_model['predsentiment'] = pred\n",
        "df_subset_train_model['predsentiment2'] = pred2\n",
        "\n",
        "print(df_subset_train_model.head())\n",
        "\n",
        "#%%\n",
        "print('\\nclassification report:\\n', classification_report(df_subset_train_model['sentiment_numeric'],df_subset_train_model['predsentiment']))\n",
        "\n",
        "df_confusion = pd.crosstab(df_subset_train_model['sentiment_numeric'], df_subset_train_model['predsentiment'], rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
        "print(df_confusion)\n",
        "\n",
        "print(df_subset_train_model.predsentiment2.apply(str).value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}